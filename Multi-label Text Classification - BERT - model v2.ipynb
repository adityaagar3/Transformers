{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314e18ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\transformers\\lib\\site-packages\\pytorch_lightning\\metrics\\__init__.py:44: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  \"`pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package\"\n"
     ]
    }
   ],
   "source": [
    "####Source: https://curiousily.com/posts/multi-label-text-classification-with-bert-and-pytorch-lightning/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BartTokenizer, BartForSequenceClassification\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc4d946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((680, 14), (121, 14))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('intent_data_model.csv',encoding='latin1')\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81970fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABEL_COLUMNS = df.columns.tolist()[2:]\n",
    "df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4030def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BART_MODEL_NAME = 'sismetanin/mbart_large-financial_phrasebank'\n",
    "tokenizer = BartTokenizer.from_pretrained(BART_MODEL_NAME)\n",
    "\n",
    "# model = BartForSequenceClassification.from_pretrained('sismetanin/mbart_large-financial_phrasebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6990965",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = df.iloc[16]\n",
    "sample_comment = sample_row.question\n",
    "sample_labels = sample_row[LABEL_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8f4611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "torch.Size([1, 256]) torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_comment,\n",
    "  add_special_tokens=True,\n",
    "  max_length=256,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "print(encoding.keys())\n",
    "print(encoding[\"input_ids\"].shape, encoding[\"attention_mask\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06ed926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_counts = []\n",
    "for _, row in train_df.iterrows():\n",
    "    token_count = len(tokenizer.encode(\n",
    "    row[\"question\"],\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    "  ))\n",
    "    token_counts.append(token_count)\n",
    "sns.histplot(token_counts)\n",
    "plt.xlim([0, 512]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1e6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6692d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDataset(Dataset):\n",
    "    def __init__(self,data: pd.DataFrame,tokenizer: BartTokenizer,max_token_len: int = 128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        comment_text = data_row.question\n",
    "        labels = data_row[LABEL_COLUMNS]\n",
    "        encoding = self.tokenizer.encode_plus(comment_text,add_special_tokens=True,max_length=self.max_token_len,\n",
    "                                              return_token_type_ids=False,padding=\"max_length\",truncation=True,\n",
    "                                              return_attention_mask=True,return_tensors='pt')\n",
    "        return dict(comment_text=comment_text,\n",
    "                    input_ids=encoding[\"input_ids\"].flatten(),\n",
    "                    attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "                    labels=torch.FloatTensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6497cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IntentDataset(train_df,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313277db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 64]), torch.Size([8, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BartForSequenceClassification.from_pretrained(BART_MODEL_NAME, return_dict=True)\n",
    "sample_batch = next(iter(DataLoader(train_dataset, batch_size=8, num_workers=0)))\n",
    "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f37bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert_model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "# output.last_hidden_state.shape, output.pooler_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4660deae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[2][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72766cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = output[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5cb2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1924, -2.0324, -2.9468, -3.2543, -2.3969,  0.9607, -3.5103, -2.7435],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46041c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = IntentDataset(self.train_df,self.tokenizer,self.max_token_len)\n",
    "        self.test_dataset = IntentDataset(self.test_df,self.tokenizer,self.max_token_len)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=0)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,batch_size=self.batch_size,num_workers=0)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,batch_size=self.batch_size,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a03d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 12\n",
    "data_module = IntentDataModule(train_df,val_df,tokenizer,batch_size=BATCH_SIZE,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dad948fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentTagger(pl.LightningModule):\n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = BartForSequenceClassification.from_pretrained(BART_MODEL_NAME, return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(output[2][:,0])\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {'val_loss': loss}\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        labels = []\n",
    "        predictions = []\n",
    "        for output in outputs:\n",
    "            for out_labels in output[\"labels\"].detach().cpu():\n",
    "                labels.append(out_labels)\n",
    "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "        labels = torch.stack(labels).int()\n",
    "        predictions = torch.stack(predictions)\n",
    "        for i, name in enumerate(LABEL_COLUMNS):\n",
    "            class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=self.n_warmup_steps,\n",
    "                                                    num_training_steps=self.n_training_steps)\n",
    "        return dict(optimizer=optimizer,lr_scheduler=dict(scheduler=scheduler,interval='step'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = nn.Linear(2, 1)\n",
    "optimizer = AdamW(params=dummy_model.parameters(), lr=0.001)\n",
    "warmup_steps = 20\n",
    "total_training_steps = 100\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=warmup_steps,num_training_steps=total_training_steps)\n",
    "learning_rate_history = []\n",
    "\n",
    "for step in range(total_training_steps):\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    learning_rate_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "plt.plot(learning_rate_history, label=\"learning rate\")\n",
    "plt.axvline(x=warmup_steps, color=\"red\", linestyle=(0, (5, 10)), label=\"warmup end\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4f2220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd67a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 5600)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38debacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IntentTagger(n_classes=len(LABEL_COLUMNS),n_warmup_steps=warmup_steps,n_training_steps=total_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12e2b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4775, 0.4909, 0.4845, 0.5151, 0.5111, 0.5157, 0.4965, 0.4998, 0.4940,\n",
       "         0.4922, 0.5057, 0.4829],\n",
       "        [0.4777, 0.4892, 0.4831, 0.5146, 0.5127, 0.5154, 0.4973, 0.5001, 0.4945,\n",
       "         0.4901, 0.5077, 0.4813],\n",
       "        [0.4780, 0.4898, 0.4843, 0.5151, 0.5115, 0.5155, 0.4978, 0.5000, 0.4945,\n",
       "         0.4894, 0.5062, 0.4834],\n",
       "        [0.4783, 0.4898, 0.4835, 0.5152, 0.5122, 0.5154, 0.4977, 0.5005, 0.4943,\n",
       "         0.4912, 0.5064, 0.4825],\n",
       "        [0.4782, 0.4880, 0.4821, 0.5140, 0.5139, 0.5152, 0.4982, 0.5005, 0.4946,\n",
       "         0.4896, 0.5088, 0.4803],\n",
       "        [0.4786, 0.4900, 0.4837, 0.5154, 0.5126, 0.5152, 0.4975, 0.5004, 0.4945,\n",
       "         0.4909, 0.5063, 0.4824],\n",
       "        [0.5026, 0.5066, 0.5120, 0.5114, 0.4825, 0.5020, 0.4993, 0.5007, 0.4944,\n",
       "         0.5075, 0.5019, 0.5067],\n",
       "        [0.4777, 0.4895, 0.4836, 0.5149, 0.5123, 0.5149, 0.4977, 0.5003, 0.4942,\n",
       "         0.4904, 0.5068, 0.4818]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ee0414f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntentTagger(\n",
       "  (bert): BartForSequenceClassification(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_head): BartClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=12, bias=True)\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion(predictions, sample_batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#   dirpath=\"/root/Aditya/\",\n",
    "#   filename=\"best-checkpoint\",\n",
    "#   save_top_k=1,\n",
    "#   verbose=True,\n",
    "#    monitor=\"val_loss\",\n",
    "#   mode=\"min\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0139c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"IntentQA_logsB\", name=\"questions-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(logger=logger,\n",
    "                     checkpoint_callback=True,\n",
    "                     callbacks=[early_stopping_callback],\n",
    "                     max_epochs=N_EPOCHS,\n",
    "                     gpus=1,\n",
    "                     progress_bar_refresh_rate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = IntentTagger.load_from_checkpoint(trainer.checkpoint_callback.best_model_path,\n",
    "                                                  n_classes=len(LABEL_COLUMNS))\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = \"I have 2 options, either invest in gold or in NASDAQ, what should i do?\"\n",
    "encoding = tokenizer.encode_plus(test_comment,\n",
    "                                 add_special_tokens=True,\n",
    "                                 max_length=512,\n",
    "                                 return_token_type_ids=False,\n",
    "                                 padding=\"max_length\",\n",
    "                                 return_attention_mask=True,\n",
    "                                 return_tensors='pt')\n",
    "\n",
    "_, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
    "test_prediction = test_prediction.flatten().numpy()\n",
    "\n",
    "for label, prediction in zip(LABEL_COLUMNS, test_prediction):\n",
    "    print(f\"{label}: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31472ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### evaluation\n",
    "val_df1 = val_df\n",
    "val_df = train_df\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "val_dataset = IntentDataset(val_df, tokenizer,max_token_len=MAX_TOKEN_COUNT)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device))\n",
    "    \n",
    "    predictions.append(prediction.flatten())\n",
    "    labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUROC per tag\")\n",
    "\n",
    "for i, name in enumerate(LABEL_COLUMNS):\n",
    "    try:\n",
    "        tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
    "        print(f\"{name}: {tag_auroc}\")\n",
    "    except:\n",
    "        print(f\"{name}:\", \" no record\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acfcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "\n",
    "upper, lower = 1, 0\n",
    "\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=LABEL_COLUMNS,\n",
    "zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### metrics on validation data\n",
    "#### evaluation\n",
    "\n",
    "val_df = val_df1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "val_dataset = IntentDataset(val_df, tokenizer,max_token_len=MAX_TOKEN_COUNT)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device))\n",
    "    \n",
    "    predictions.append(prediction.flatten())\n",
    "    labels.append(item[\"labels\"].int())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "accuracy(predictions, labels, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e11ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUROC per tag\")\n",
    "\n",
    "for i, name in enumerate(LABEL_COLUMNS):\n",
    "    try:\n",
    "        tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
    "        print(f\"{name}: {tag_auroc}\")\n",
    "    except:\n",
    "        print(f\"{name}:\", \" no record\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "\n",
    "upper, lower = 1, 0\n",
    "\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=LABEL_COLUMNS,\n",
    "zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_rate, true_pos_rate, proba = roc_curve(y_test, predicted_proba[:, -1])\n",
    "\n",
    "optimal_proba_cutoff = sorted(list(zip(np.abs(true_pos_rate - false_pos_rate), proba)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "roc_predictions = [1 if i >= optimal_proba_cutoff else 0 for i in predicted_proba[:, -1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
